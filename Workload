    command: uvicorn main:app --host 0.0.0.0 --port 8000


  image: traefik:latest
  volumes:
    - /var/run/docker.sock:/var/run/docker.sock
  command:
    --docker
    --docker.swarmmode
    --docker.watch
    --docker.exposedbydefault=false
    --entrypoints='Name:http Address::80'
    --consul
    --consul.endpoint="consul-leader:8500"
    --logLevel=INFO
    --accessLog
    --api
  ports:
    - target: 80
      published: 80
      mode: host
    - target: 8080
      published: 8080
      mode: host
    --constraints=tag==traefik-public
    --acme
    --acme.email=${EMAIL}
    --acme.storage="traefik/acme/account"
    --acme.entryPoint=https
    --acme.httpChallenge.entryPoint=http
    --acme.onhostrule=true
    --acme.acmelogging=true

    --entrypoints='Name:https Address::443 TLS'




!pip install minio
!pip install sqlalchemy
!pip install pymysql
!pip install pandas
!pip install sklearn
!pip install psycopg2-binary
#Scitkit
from sklearn import svm
from sklearn.model_selection import train_test_split
import os
from sklearn import metrics
from sklearn.externals import joblib

# Postgres
import pandas as pd
import sqlalchemy
from sqlalchemy import create_engine

# Postgres username, password, and database name
DIALECT = "mysql+pymysql"
DB_ADDRESS = "10.0.0.143"
DB_PORT = "3306"
DB_USERNAME = "root"
DB_PASSWORD = "admin"
DB_NAME = "test"
# A long string that contains the necessary Postgres login information
db_str = ('{dialect}://{username}:{password}@{ipaddress}/{dbname}'.format(dialect=DIALECT,
                                                                                username=DB_USERNAME,
                                                                                password=DB_PASSWORD,
                                                                                ipaddress=DB_ADDRESS,
                                                                                dbname=DB_NAME))
print(db_str)
# Create the connection
cnx = create_engine(db_str)

#Read
data_frame = pd.read_sql_query('''SELECT * FROM train_table''', cnx)

print(data_frame)
#Train Model




#Scitkit
from sklearn import svm
from sklearn.model_selection import train_test_split
import os
from sklearn import metrics
from sklearn.externals import joblib

# Postgres
import pandas as pd
import sqlalchemy
from sqlalchemy import create_engine

send_frame = pd.read_csv("./datasets/small_dataset.csv")
#print(send_frame.head(1))


# Postgres username, password, and database name
DIALECT = "postgresql"
DB_ADDRESS = "database"
DB_PORT = "5432"
DB_USERNAME = "admin"
DB_PASSWORD = "admin"
DB_NAME = "test"
# A long string that contains the necessary Postgres login information
db_str = ('{dialect}://{username}:{password}@{ipaddress}/{dbname}'.format(dialect=DIALECT,
                                                                                username=DB_USERNAME,
                                                                                password=DB_PASSWORD,
                                                                                ipaddress=DB_ADDRESS,
                                                                                dbname=DB_NAME))
print(db_str)
# Create the connection
cnx = create_engine(db_str)

send_frame.to_sql("train_table" con=cnx, if_exists='replace')

#Read
data_frame = pd.read_sql_query('''SELECT * FROM train_table''', cnx)

print(data_frame)
#Train Model



mlstack_database.1.orri4ar8icxq@standardheld-MS-7B78    | 2019-06-27T00:59:01.165730Z 0 [Note] mysqld (mysqld 5.7.26) starting as process 1 ...
mlstack_database.1.orri4ar8icxq@standardheld-MS-7B78    | 2019-06-27T00:59:01.167658Z 0 [Note] InnoDB: PUNCH HOLE support available
mlstack_database.1.orri4ar8icxq@standardheld-MS-7B78    | 2019-06-27T00:59:01.167669Z 0 [Note] InnoDB: Mutexes and rw_locks use GCC atomic builtins
mlstack_database.1.orri4ar8icxq@standardheld-MS-7B78    | 2019-06-27T00:59:01.167672Z 0 [Note] InnoDB: Uses event mutexes
mlstack_database.1.orri4ar8icxq@standardheld-MS-7B78    | 2019-06-27T00:59:01.167674Z 0 [Note] InnoDB: GCC builtin __atomic_thread_fence() is used for memory barrier
mlstack_database.1.orri4ar8icxq@standardheld-MS-7B78    | 2019-06-27T00:59:01.167676Z 0 [Note] InnoDB: Compressed tables use zlib 1.2.11
mlstack_database.1.orri4ar8icxq@standardheld-MS-7B78    | 2019-06-27T00:59:01.167678Z 0 [Note] InnoDB: Using Linux native AIO
mlstack_database.1.orri4ar8icxq@standardheld-MS-7B78    | 2019-06-27T00:59:01.167822Z 0 [Note] InnoDB: Number of pools: 1
mlstack_database.1.orri4ar8icxq@standardheld-MS-7B78    | 2019-06-27T00:59:01.167886Z 0 [Note] InnoDB: Using CPU crc32 instructions
mlstack_database.1.orri4ar8icxq@standardheld-MS-7B78    | 2019-06-27T00:59:01.169170Z 0 [Note] InnoDB: Initializing buffer pool, total size = 128M, instances = 1, chunk size = 128M
mlstack_database.1.orri4ar8icxq@standardheld-MS-7B78    | 2019-06-27T00:59:01.174258Z 0 [Note] InnoDB: Completed initialization of buffer pool
mlstack_database.1.orri4ar8icxq@standardheld-MS-7B78    | 2019-06-27T00:59:01.175717Z 0 [Note] InnoDB: If the mysqld execution user is authorized, page cleaner thread priority can be changed. See the man page of setpriority().
mlstack_database.1.orri4ar8icxq@standardheld-MS-7B78    | 2019-06-27T00:59:01.187518Z 0 [Note] InnoDB: Highest supported file format is Barracuda.
mlstack_database.1.orri4ar8icxq@standardheld-MS-7B78    | 2019-06-27T00:59:01.187621Z 0 [ERROR] InnoDB: Unsupported redo log format. The redo log was created with MariaDB 10.4.6. Please follow the instructions at http://dev.mysql.com/doc/refman/5.7/en/upgrading-downgrading.html
mlstack_database.1.orri4ar8icxq@standardheld-MS-7B78    | 2019-06-27T00:59:01.187634Z 0 [ERROR] InnoDB: Plugin initialization aborted with error Generic error
mlstack_database.1.orri4ar8icxq@standardheld-MS-7B78    | 2019-06-27T00:59:01.788083Z 0 [ERROR] Plugin 'InnoDB' init function returned error.
mlstack_database.1.orri4ar8icxq@standardheld-MS-7B78    | 2019-06-27T00:59:01.788108Z 0 [ERROR] Plugin 'InnoDB' registration as a STORAGE ENGINE failed.
mlstack_database.1.orri4ar8icxq@standardheld-MS-7B78    | 2019-06-27T00:59:01.788113Z 0 [ERROR] Failed to initialize builtin plugins.
mlstack_database.1.orri4ar8icxq@standardheld-MS-7B78    | 2019-06-27T00:59:01.788116Z 0 [ERROR] Aborting
mlstack_database.1.orri4ar8icxq@standardheld-MS-7B78    |
mlstack_database.1.orri4ar8icxq@standardheld-MS-7B78    | 2019-06-27T00:59:01.788130Z 0 [Note] Binlog end
mlstack_database.1.orri4ar8icxq@standardheld-MS-7B78    | 2019-06-27T00:59:01.788180Z 0 [Note] Shutting down plugin 'CSV'
mlstack_database.1.orri4ar8icxq@standardheld-MS-7B78    | 2019-06-27T00:59:01.789733Z 0 [Note] mysqld: Shutdown complete
mlstack_database.1.orri4ar8icxq@standardheld-MS-7B78    |




#Scitkit
from sklearn import svm
from sklearn.model_selection import train_test_split
import os
from sklearn import metrics
from sklearn.externals import joblib

# Postgres
import pandas as pd
import sqlalchemy
from sqlalchemy import create_engine

send_frame = pd.read_csv("./datasets/small_dataset.csv")
#print(send_frame.head(1))

new_frame = send_frame.iloc[:10]
print(new_frame)

# Postgres username, password, and database name
DIALECT = "postgresql"
DB_ADDRESS = "database"
DB_PORT = "5432"
DB_USERNAME = "admin"
DB_PASSWORD = "admin"
DB_NAME = "test"
# A long string that contains the necessary Postgres login information
db_str = ('{dialect}://{username}:{password}@{ipaddress}/{dbname}'.format(dialect=DIALECT,
                                                                                username=DB_USERNAME,
                                                                                password=DB_PASSWORD,
                                                                                ipaddress=DB_ADDRESS,
                                                                                dbname=DB_NAME))
print(db_str)
# Create the connection
cnx = create_engine(db_str)
d6tstack.utils.pd_to_psql(send_frame, db_str, 'train_table',if_exists='replace')

new_frame.to_sql('train_table', con=cnx, if_exists='append')

#Read
data_frame = pd.read_sql_query('''SELECT * FROM train_table''', cnx)

print(data_frame)
#Train Model







#Scitkit
from sklearn import svm
from sklearn.model_selection import train_test_split
import os
from sklearn import metrics
from sklearn.externals import joblib

# Postgres
import pandas as pd
import sqlalchemy
from sqlalchemy import create_engine
import d6tstack
send_frame = pd.read_csv("./datasets/small_dataset.csv")
print(send_frame.shape)

#new_frame = send_frame.iloc[:10000]
#print(new_frame)

# Postgres username, password, and database name
DIALECT = "postgresql+psycopg2"
DB_ADDRESS = "database"
DB_PORT = "5432"
DB_USERNAME = "admin"
DB_PASSWORD = "admin"
DB_NAME = "test"
# A long string that contains the necessary Postgres login information
db_str = ('{dialect}://{username}:{password}@{ipaddress}/{dbname}'.format(dialect=DIALECT,
                                                                                username=DB_USERNAME,
                                                                                password=DB_PASSWORD,
                                                                                ipaddress=DB_ADDRESS,
                                                                                dbname=DB_NAME))
print(db_str)
# Create the connection
cnx = create_engine(db_str)

d6tstack.utils.pd_to_psql(send_frame, db_str, 'train_table',if_exists='replace')

#new_frame.to_sql('train_table', con=cnx, if_exists='append')
print("Sent Frame")
#Read
data_frame = pd.read_sql_query('''SELECT * FROM train_table''', cnx)

print(data_frame)
#Train Model





#Scitkit
from sklearn import svm
from sklearn.model_selection import train_test_split
import os
from sklearn import metrics
from sklearn.externals import joblib

# Postgres
import pandas as pd
import sqlalchemy
from sqlalchemy import create_engine
from pymongo import MongoClient

send_frame = pd.read_csv("./datasets/small_dataset.csv")
#print(send_frame.shape)

new_frame = send_frame.iloc[:10000]
#print(new_frame)

# Postgres username, password, and database name
DIALECT = "mongodb"
DB_ADDRESS = "database"
DB_PORT = "27017"
DB_USERNAME = "admin"
DB_PASSWORD = "admin"
DB_NAME = "admin"
# A long string that contains the necessary Postgres login information
db_str = ('{dialect}://{username}:{password}@{ipaddress}/{dbname}'.format(dialect=DIALECT,
                                                                                username=DB_USERNAME,
                                                                                password=DB_PASSWORD,
                                                                                ipaddress=DB_ADDRESS,
                                                                                dbname=DB_NAME))
print(db_str)
# Create the connection

client = MongoClient(db_str)
db = client.test
db = db.train_table
db.insert_many(new_frame.to_dict('records'))

print("Sent Frame")


#select the collection within the database
test = db.test
#convert entire collection to Pandas dataframe
data = pd.DataFrame(list(db.find()))

print(data)
#Read
#data_frame = pd.read_sql_query('''SELECT * FROM train_table''', cnx)

#print(data_frame)
#Train Model
